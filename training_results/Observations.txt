Pre-trained networks used for each experiment:
=======================================
	-> DenseNet121, EfficientNetB0, EfficientNetB1, EfficientNetB2, InceptionV3,
	MobileNet, MobileNetV2, ResNet50, ResNet50V2, Xception
	-> These networks were chosen because they are all maximum 100 MB in size and
	have at most 25 million parameters. These models are regarded as being
	relatively small, which is suitable for our application
	-> These networks are used as the basis of our models; the learning is
	performed by freezing the weights of the pre-trained network, then adding
	additional layers on top of it, which are then trained on our dataset
	-> The pre-trained networks used, in decreasing order of their accuracy on
	the ImageNet dataset: EfficientNetB2 (79.9), Xception (79), EfficientNetB1 (78,8),
	InceptionV3 (77,9), EfficientNetB0 (76,6), ResNet50V2 (76), ResNet50 (74,9),
	DenseNet121 (75), MobileNetV2 (71.3), MobileNet (70.4)
	-> More information about the models used can be found here: https://keras.io/api/applications/
	
Architectures used for each training run:
=======================================
	run_1 -> Base Model -> Avg Pooling 2D -> Dropout 0.5 -> Dense 10
	run_2 -> Base Model -> Flatten -> Dense 1024 -> Dropout 0.5 -> Dense 10
	run_3 -> Base Model -> Flatten -> Dense 512 -> Dropout 0.5 -> Dense 10
	run_4 -> Base Model -> Flatten -> Dense 256 -> Dropout 0.5 -> Dense 10
	run_5 -> Base Model -> Max Pooling 2D -> Flatten -> Dense 256 -> Dropout 0.5 -> Dense 10
	run_6 -> Base Model -> Max Pooling 2D -> Dense 128 -> Dropout 0.5 -> Dense 10

Results analysis:
=======================================
	- The 
	run_1:
	- The model used in run_1 is the simplest, because it doesn't use any Fully
		Connected layers for specializing the network on our dataset
	- The training and validation accuracy hardly surpassed 30% and the loss
	revolved around 2.0




